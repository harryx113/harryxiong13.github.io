<!doctype html>
<html>
    <head>
        <title>Harry Xiong</title>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
        <link rel="stylesheet" href="https://use.typekit.net/fwo1rup.css">
        <link rel="stylesheet" type="text/css" href="style2.css">
    </head>

    <body>

        <nav class="navbar navbar-expand-lg navbar-light bg-light">
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class = "nav" href = "https://harry-xiong.com">home</a>
                    </li>
                    <li class="nav-item">
                        <a class = "nav" href = "https://harry-xiong.com/#about-me">about</a>
                    </li>
                    <li class="nav-item">
                        <a class = "nav" href="https://harry-xiong.com/#intro-page">resume</a>
                    </li>
                    <li class="nav-item">
                        <a class = "nav" href = "https://harry-xiong.com/#ds-projects">projects</a>
                    </li>
                </ul>
            </div>
        </nav>

        <div class = "content">

            <h1>Caption Generator</h1>
            <h2 class = "project-date">Aug, 2020</h2>
            <h2 class = "project-technology-section">
                <span class = project-technology>Deep Learning</span>
                <span class = project-technology>Object Recognition</span>
                <span class = project-technology>Text Generation</span>
            </h2>
            <a href="https://github.com/harryxiong13/caption-generator">GitHub Repo</a>
            <img src="../assets/caption-overall.png" class = "project-pic">
            <span class = "project-description">
              This caption generator can read an image, extract its features, and generate a caption accordingly.
              The implication of this project is significant. Not only can people use it to automatically translate images to words, with a little fine-tuning,
              e-commerce sites like Etsy, Wish and Ebay could help their sellers to create item titles and descriptions;
              with text-to-voice technology, people with visual impairment can read an image just like everyone.
            </span>
            <img src="../assets/caption-1.png" class = "project-pic">
            <span class = "project-description">
              This project uses a CNN feature extraction + LSTM text generation architecture. For feature extraction, Xception, a pre-trained model similar to Inception V3,
              is used and LSTM is used in parallel to process the text input from the dataset.
            </span>
            <img src="../assets/caption-2.jpeg" class = "project-pic">
            <span class = "project-description">
              The Flickr_8K dataset contains more than 8000 images and respective captions.
              The topics covered in this dataset include animals, sports, street views, human activities and so on.
            </span>
            <img src="../assets/caption-demo1.gif" class = "project-pic">
            <img src="../assets/caption-demo2.gif" class = "project-pic">
            <span class = "project-description">
              Demos. To learn more about it and use it, you can visit the github repo <a href="https://github.com/harryxiong13/caption-generator">here</a>.
            </span>

        </div>

    </body>
</html>
